{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import newspaper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required module\n",
    "\n",
    "\n",
    "# Assign url\n",
    "urls = ['https://www.geeksforgeeks.org/top-5-open-source-online-machine-learning-environments/',\n",
    "        'https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjI56vC3MH9AhUP8zgGHbryB0sQvOMEKAB6BAgOEAE&url=https%3A%2F%2Fwww.thehindu.com%2Fnews%2Finternational%2Fquad-foreign-ministers-take-aim-at-russia-and-china%2Farticle66577074.ece&usg=AOvVaw3G125a3AJkzEiMjMpC3Tt_',\n",
    "        'https://www.thehindu.com/news/national/better-infrastructure-has-put-remote-indian-villages-on-tourist-map-pm-modi/article66575058.ece',\n",
    "        'https://www.thehindu.com/sci-tech/health/avoid-antibiotics-for-seasonal-cold-and-cough-says-indian-medical-association-amid-rising-cases/article66579326.ece',\n",
    "        ]\n",
    "\n",
    "# Extract web data\n",
    "articles = []\n",
    "for url in urls:\n",
    "    article = newspaper.Article(url=\"%s\" % (url), language='en')\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    articles.append({\n",
    "        'title': article.title,\n",
    "        'text': article.text\n",
    "    })\n",
    "\n",
    "# Display scrapped data\n",
    "#articles[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list = articles\n",
    "keywords_dict = {\n",
    "    'atm': ['any time money', 'automatic teller machine', ],\n",
    "    'Machine Learning' : ['ml', 'ai'],\n",
    "    'theft': ['robbery', 'steal', 'larceny'],\n",
    "    'party': ['political', 'bjp', 'congress']\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def removePunctuations(news_list):\n",
    "    for i in range(len(news_list)):\n",
    "        news_text = news_list[i]['text']\n",
    "        news_list[i]['text'] = re.sub(r'[^\\w\\s]', '', news_text)\n",
    "        news_title = news_list[i]['title']\n",
    "        news_list[i]['title'] = re.sub(r'[^\\w\\s]', '', news_title)\n",
    "    \n",
    "    return news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading_priority = 10\n",
    "content_priority = 8\n",
    "\n",
    "priority = list(np.arange(len(keywords_dict))[::-1]+1)\n",
    "news_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(words):\n",
    "    score = 0\n",
    " \n",
    "    for i in range(len(words)):\n",
    "        for j in range(len(keywords_dict)):\n",
    "            keyword = list(keywords_dict.keys())[j]\n",
    "            lis = [keyword]+keywords_dict[keyword]\n",
    "            for synonym in lis:\n",
    "                if len(synonym.split(' ')) < 2:\n",
    "                    if words[i] == synonym:\n",
    "                        score += len(keywords_dict) - j\n",
    "                else:\n",
    "                    l = 0\n",
    "                    index = i\n",
    "                    while(l < len(synonym.split(' ')) and words[i] == synonym.split(' ')[l]):\n",
    "                        i += 1\n",
    "                        l += 1\n",
    "                    if(l == len(synonym.split(' '))):\n",
    "                        score += priority[j]\n",
    "                    else:\n",
    "                        i = index   \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "0\n",
      "8\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'Top 5 OpenSource Online Machine Learning Environments',\n",
       " 'text': 'Machine Learning is an area of research that allows machines the ability to learn without being directly programmed Machine Learning development is in trend as many students teachers developers and data scientists use machine learning to develop various projects and products However developing machine learning models require high system requirement specifications as sometimes the model training process can go from 2 hours to 2 days and more So lowend systems can not handle training of good machine learning models or even if they somehow train models critical system issues are likely to occur\\n\\nHowever there are many opensource Machine Learning environments available that do not require any system requirement specification and use cloud infrastructure to train your model in the most optimal time possible Below are the most efficient commonly used online machine learning environments\\n\\nIts a cloud service that can be easily accessed to develop products and projects provided by Google It supports free GPUs and is based on the Jupyter Notebooks setting It provides a forum for everyone to build machine learning and deep learning applications using widely used libraries like PyTorch TensorFlow and Keras It offers a way for your system not to take out the full workload of your ML activities Its one of the most successful platforms of its kind\\n\\nRAM  12 GB to 2675 GB\\n\\nDisk Space  25 GB\\n\\n 25 GB CPU Cores  2\\n\\n 2 Languages Supported  Python\\n\\nIBM launched the Watson Data Platform and Data Science Experience DSX to support opensource solutions Eventually it launched the multicloud freedom of choice platform for data science work This was achieved with the help of containerization of the stock by Kubernetes As a consequence it can be distributed in Docker or CloudFoundry containers wherever the data is stored\\n\\nRAM  16 GB\\n\\nDisk Space  90 GB\\n\\n 90 GB CPU Cores  4\\n\\n 4 Languages Supported  Apache Spark Python R Scala\\n\\nIts an excellent platform for deep learning and machine learning applications in the cloud Kaggle and Colab have a variety of similarities both being Google products It supports the Jupyter Notebooks in the browser Many of the Jupyter Notebook keyboard shortcuts are almost the same as Kaggle Kaggle has a large collection of datasets and has a broad community devoted to promoting learning and validating data science skills The use of GPU and TPU has some usage restrictions in the Kaggle kernel\\n\\nRAM  25 GB\\n\\nDisk Space  155 GB\\n\\n 155 GB CPU Cores  1\\n\\n 1 Languages Supported  Python R\\n\\nIt is a virtual online workspace for computing research collaboration and writing documents This includes working with the full range of scientific languages provides author text functionality in LaTeX Rknitr or Markdown a webbased Linux console time travel feature and networking resources such as chat rooms course management and more However most of its features come under a paid plan\\n\\nRAM  16 GB\\n\\nDisk Space  20 GB\\n\\n 20 GB CPU Cores  3\\n\\n 3 Languages Supported  Julia Octave Python SageMath R Statistics etc\\n\\nMicrosofts Azure notebooks are somewhat similar in functionality to Colab but it wins in terms of speed and is much better than Colab in this respect Azure Notebooks is a series of linked notebooks called Libraries These libraries are smaller than 100 megabytes in size of each data file Azure Notebooks are more suited for basic applications Azure provides only 12 months of free service\\n\\nRAM  Variable\\n\\nDisk Space  Variable\\n\\n CPU Cores  Variable\\n\\n Languages Supported  Python R F'}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_list = removePunctuations(news_list)\n",
    "for news in news_list:\n",
    "    score = 0\n",
    "    score += content_priority*getScore(news['text'].split(' '))\n",
    "    score += heading_priority*getScore(news['title'].split(' '))    \n",
    "    print(score)\n",
    "    news_scores.append(score)\n",
    "\n",
    "index = news_scores.index(max(news_scores))\n",
    "news_list[index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
